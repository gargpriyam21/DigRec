{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "%matplotlib inline\n",
    "plt.rcParams['figure.figsize'] = (16.0, 4.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#loading the data\n",
    "from scipy.io import loadmat\n",
    "\n",
    "def load_data(path):\n",
    "    data = loadmat(path)\n",
    "    return data['X'], data['y']\n",
    "\n",
    "X_train, y_train = load_data('data/train_32x32.mat')\n",
    "X_test, y_test = load_data('data/test_32x32.mat')\n",
    "X_extra, y_extra = load_data('data/extra_32x32.mat')\n",
    "\n",
    "print(\"Training\", X_train.shape, y_train.shape)\n",
    "print(\"Testing\", X_test.shape, y_test.shape)\n",
    "print(\"Extra\", X_extra.shape, y_extra.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Transpose the image arrays\n",
    "X_train, y_train = X_train.transpose((3,0,1,2)), y_train[:,0]\n",
    "X_test, y_test = X_test.transpose((3,0,1,2)), y_test[:,0]\n",
    "X_extra, y_extra = X_extra.transpose((3,0,1,2)), y_extra[:,0]\n",
    "\n",
    "print(\"Training\", X_train.shape)\n",
    "print(\"Test\", X_test.shape)\n",
    "print(\"Extra\", X_extra.shape)\n",
    "print('')\n",
    "\n",
    "# Calculate the total number of images\n",
    "num_images = X_train.shape[0] + X_test.shape[0] + X_extra.shape[0]\n",
    "\n",
    "print(\"Total Number of Images\", num_images)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_images(img, labels, nrows, ncols):\n",
    "    fig, axes = plt.subplots(nrows, ncols)\n",
    "    for i, ax in enumerate(axes.flat):\n",
    "        if img[i].shape == (32, 32, 3):\n",
    "            ax.imshow(img[i])\n",
    "        else:\n",
    "            ax.imshow(img[i,:,:,0])\n",
    "        ax.set_xticks([]); ax.set_yticks([])\n",
    "        ax.set_title(labels[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_images(X_train, y_train, 2, 8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_images(X_test, y_test, 2, 8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_images(X_test, y_test, 2, 8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(np.unique(y_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, (ax1, ax2, ax3) = plt.subplots(1, 3, sharex = True)\n",
    "fig.suptitle('Class Distribution', fontsize=14, fontweight='bold', y=1.05)\n",
    "\n",
    "ax1.hist(y_train, bins=10)\n",
    "ax1.set_title(\"Training set\")\n",
    "ax1.set_xlim(1, 10)\n",
    "\n",
    "ax2.hist(y_test, color='g', bins=10)\n",
    "ax2.set_title(\"Test set\")\n",
    "\n",
    "ax3.hist(y_extra, color='r', bins=10);\n",
    "ax3.set_title(\"Extra set\");\n",
    "\n",
    "fig.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#the label of 0 is given as 10 in the y_train array, so re assign it to 0\n",
    "y_train[y_train== 10] = 0\n",
    "y_test[y_test== 10] = 0\n",
    "y_extra[y_extra== 10] = 0\n",
    "\n",
    "#testing the changes made\n",
    "print(np.unique(y_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#creating a balanced data set by making a new validation set comprising 2/3 of the test samples, \n",
    "#and 1/3 of the extra samples. Total samples taken will be 6000 (600 for each class)\n",
    "# s=size of sample, y = np.array\n",
    "def balanced_subsample(y, s):\n",
    "    sample = []\n",
    "    for label in np.unique(y):\n",
    "        images = np.where(y==label)[0]\n",
    "        random_sample = np.random.choice(images, size = s, replace = False)\n",
    "        sample += random_sample.tolist()\n",
    "    return sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_samples = balanced_subsample(y_train, 400)\n",
    "extra_samples = balanced_subsample(y_extra, 200)\n",
    "\n",
    "X_val, y_val = np.copy(X_train[train_samples]), np.copy(y_train[train_samples])\n",
    "\n",
    "# Remove the samples to avoid duplicates\n",
    "X_train = np.delete(X_train, train_samples, axis=0)\n",
    "y_train = np.delete(y_train, train_samples, axis=0)\n",
    "\n",
    "X_val = np.concatenate([X_val, np.copy(X_extra[extra_samples])])\n",
    "y_val = np.concatenate([y_val, np.copy(y_extra[extra_samples])])\n",
    "\n",
    "# Remove the samples to avoid duplicates\n",
    "X_extra = np.delete(X_extra, extra_samples, axis=0)\n",
    "y_extra = np.delete(y_extra, extra_samples, axis=0)\n",
    "\n",
    "X_train = np.concatenate([X_train, X_extra])\n",
    "y_train = np.concatenate([y_train, y_extra])\n",
    "X_test, y_test = X_test, y_test\n",
    "\n",
    "print(\"Training\", X_train.shape, y_train.shape)\n",
    "print(\"Test\", X_test.shape, y_test.shape)\n",
    "print('Validation', X_val.shape, y_val.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, (ax1, ax2, ax3) = plt.subplots(1, 3, sharex=True)\n",
    "\n",
    "fig.suptitle('Class Distribution', fontsize=14, fontweight='bold', y=1.05)\n",
    "\n",
    "ax1.hist(y_train, bins=10)\n",
    "ax1.set_title(\"Training set\")\n",
    "ax1.set_xlim(0, 9)\n",
    "\n",
    "ax2.hist(y_test, color='g', bins=10)\n",
    "ax2.set_title(\"Test set\")\n",
    "\n",
    "ax3.hist(y_val, color='r', bins=10);\n",
    "ax3.set_title(\"Validation set\");\n",
    "\n",
    "fig.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert(num_images == X_train.shape[0] + X_test.shape[0] + X_val.shape[0])\n",
    "plot_images(X_train, y_train, 2, 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_images(X_test, y_test, 2, 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_images(X_test, y_test, 2, 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_images(X_test, y_test, 2, 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "suffixes = ['B', 'KB', 'MB', 'GB']\n",
    "\n",
    "def humansize(nbytes):\n",
    "    if nbytes == 0: return '0 B'\n",
    "    i = 0\n",
    "    while nbytes >= 1024:\n",
    "        nbytes /= 1024.\n",
    "        i += 1\n",
    "    f = ('%.2f' % nbytes).rstrip('0').rstrip('.')\n",
    "    return '%s %s' % (f, suffixes[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rgb2gray(images):\n",
    "    \"\"\"Convert images from rgb to grayscale\n",
    "    \"\"\"\n",
    "    return np.expand_dims(np.dot(images, [0.2989, 0.5870, 0.1140]), axis=3)\n",
    "\n",
    "# Transform the images to greyscale\n",
    "train_greyscale = rgb2gray(X_train).astype(np.float32)\n",
    "test_greyscale = rgb2gray(X_test).astype(np.float32)\n",
    "valid_greyscale = rgb2gray(X_val).astype(np.float32)\n",
    "\n",
    "# Keep the size before convertion\n",
    "size_before = (X_train.nbytes, X_test.nbytes, X_val.nbytes)\n",
    "\n",
    "# Size after transformation\n",
    "size_after = (train_greyscale.nbytes, test_greyscale.nbytes, valid_greyscale.nbytes)\n",
    "\n",
    "print(\"Dimensions\")\n",
    "print(\"Training set\", X_train.shape, train_greyscale.shape)\n",
    "print(\"Test set\", X_test.shape, test_greyscale.shape)\n",
    "print(\"Validation set\", X_val.shape, valid_greyscale.shape)\n",
    "print('')\n",
    "\n",
    "print(\"Data Type\")\n",
    "print(\"Training set\", X_train.dtype, train_greyscale.dtype)\n",
    "print(\"Test set\", X_test.dtype, test_greyscale.dtype)\n",
    "print(\"Validation set\", X_val.dtype, valid_greyscale.dtype)\n",
    "print('')\n",
    "\n",
    "print(\"Dataset Size\")\n",
    "print(\"Training set\", humansize(size_before[0]), humansize(size_after[0]))\n",
    "print(\"Test set\", humansize(size_before[1]), humansize(size_after[1]))\n",
    "print(\"Validation set\", humansize(size_before[2]), humansize(size_after[2]))\n",
    "\n",
    "plot_images(X_train, y_train, 1, 10)\n",
    "plot_images(train_greyscale, y_train, 1, 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_images(test_greyscale, y_test, 1,10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import OneHotEncoder\n",
    " \n",
    "# Fit the OneHotEncoder\n",
    "enc = OneHotEncoder().fit(y_train.reshape(-1, 1))\n",
    "\n",
    "# Transform the label values to a one-hot-encoding scheme\n",
    "y_train = enc.transform(y_train.reshape(-1, 1)).toarray()\n",
    "y_test = enc.transform(y_test.reshape(-1, 1)).toarray()\n",
    "y_val = enc.transform(y_val.reshape(-1, 1)).toarray()\n",
    "\n",
    "print(\"Training set\", y_train.shape)\n",
    "print(\"Test set\", y_test.shape)\n",
    "print(\"Training set\", y_val.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#saving the greyscale images\n",
    "import h5py\n",
    "\n",
    "# Create file\n",
    "h5f = h5py.File('data/SVHN_single_grey.h5', 'w')\n",
    "\n",
    "# Store the datasets\n",
    "h5f.create_dataset('X_train', data=train_greyscale)\n",
    "h5f.create_dataset('y_train', data=y_train)\n",
    "h5f.create_dataset('X_test', data=test_greyscale)\n",
    "h5f.create_dataset('y_test', data=y_test)\n",
    "h5f.create_dataset('X_val', data=valid_greyscale)\n",
    "h5f.create_dataset('y_val', data=y_val)\n",
    "\n",
    "# Close the file\n",
    "h5f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
